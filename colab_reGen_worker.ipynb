{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE1BHRAe1xPq"
      },
      "source": [
        "# Install the New Worker- No more BETA!!\n",
        "### Remember to first set your API KEY and worker name\n",
        "#### You can serve different models, simply change the name in models_to_load to match the model you want, you can check either https://aqualxx.github.io/stable-ui/workers, in the models tab, or https://tinybots.net/artbot/info/models, or https://aihorde.sitew3.com/ also in the models tab (this one also includes text gen models); just copy paste the name (it's set to Deliberate by default)\n",
        "#### You can also change max_power and see how high you can go, it's set to 20 by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NIAhaFRX1cB2",
        "outputId": "347eff2a-2092-4314-b096-c349d731b5ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"3DKX\", \"526Mix-Animated\", \"A-Zovya RPG Inpainting\", \"AAM XL\", \"ACertainThing\", \"AIO Pixel Art\", \"AMPonyXL\", \"AbsoluteReality\", \"Abyss OrangeMix\", \"AbyssOrangeMix-AfterDark\", \"AlbedoBase XL (SDXL)\", \"Analog Diffusion\", \"Analog Madness\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Anime Pencil Diffusion\", \"AnyLoRA\", \"Anygen\", \"Anything Diffusion Inpainting\", \"Anything Diffusion\", \"Anything v3\", \"Anything v5\", \"App Icon Diffusion\", \"Art Of Mtg\", \"Aurora\", \"BB95 Furry Mix v14\", \"BB95 Furry Mix\", \"BPModel\", \"BRA\", \"Babes\", \"Blank Canvas XL\", \"BlenderMix Pony\", \"BweshMix\", \"CamelliaMix 2.5D\", \"Cetus-Mix\", \"Char\", \"CharHelper\", \"Cheese Daddys Landscape Mix\", \"Cheyenne\", \"ChilloutMix\", \"Classic Animation Diffusion\", \"Colorful\", \"Comic-Diffusion\", \"Counterfeit\", \"CyberRealistic\", \"CyriousMix\", \"DGSpitzer Art Diffusion\", \"Dan Mumford Style\", \"Dark Sushi Mix\", \"Deliberate 3.0\", \"Deliberate Inpainting\", \"Deliberate\", \"Disco Elysium\", \"Disney Pixar Cartoon Type A\", \"DnD Item\", \"DnD Map Generator\", \"Double Exposure Diffusion\", \"DreamLikeSamKuvshinov\", \"DreamShaper Inpainting\", \"DreamShaper XL\", \"Dreamlike Diffusion\", \"Dreamlike Photoreal\", \"Dreamshaper\", \"DucHaiten Classic Anime\", \"DucHaiten GameArt (Unreal) Pony\", \"DucHaiten\", \"Dungeons and Diffusion\", \"Dungeons n Waifus\", \"Edge Of Realism\", \"Eimis Anime Diffusion\", \"Elysium Anime\", \"Epic Diffusion Inpainting\", \"Epic Diffusion\", \"Ether Real Mix\", \"ExpMix Line\", \"Experience\", \"FaeTastic\", \"Fantasy Card Diffusion\", \"Flat-2D Animerge\", \"Fluffusion\", \"Flux.1-Schnell fp16 (Compact)\", \"Flux.1-Schnell fp8 (Compact)\", \"Furry Epoch\", \"Fustercluck\", \"GTA5 Artwork Diffusion\", \"Galena Redux\", \"Ghibli Diffusion\", \"GhostMix\", \"GorynichMix\", \"Grapefruit Hentai\", \"Graphic-Art\", \"HASDX\", \"HRL\", \"Hassaku\", \"Healy's Anime Blend\", \"Henmix Real\", \"Hentai Diffusion\", \"ICBINP - I Can't Believe It's Not Photography\", \"ICBINP XL\", \"Illuminati Diffusion\", \"Inkpunk Diffusion\", \"JWST Deep Space Diffusion\", \"Jim Eidomode\", \"Juggernaut XL\", \"Kenshi\", \"Laolei New Berry Protogen Mix\", \"Lawlas's yiff mix\", \"Liberty\", \"Lyriel\", \"MHXL - Aventis Horizon\", \"Mega Merge Diffusion\", \"MeinaMix\", \"Microcritters\", \"Microworlds\", \"Midjourney PaintArt\", \"Mistoon Amethyst\", \"ModernArt Diffusion\", \"MoonMix Fantasy\", \"Movie Diffusion\", \"Neurogen\", \"NeverEnding Dream\", \"Nitro Diffusion\", \"Nova Anime XL\", \"Nova Furry Pony\", \"Openniji\", \"PPP\", \"Papercut Diffusion\", \"Pastel Mix\", \"Perfect World\", \"Photon\", \"Poison\", \"Pokemon3D\", \"Pony Diffusion XL\", \"Pony Realism\", \"Prefect Pony\", \"Pretty 2.5D\", \"Project Unreal Engine 5\", \"ProtoGen\", \"Protogen Anime\", \"Pulp Vector Art\", \"Quiet Goodnight XL\", \"RPG\", \"Real Dos Mix\", \"RealBiter\", \"Realisian\", \"Realism Engine\", \"Realistic Vision Inpainting\", \"Realistic Vision\", \"Reliberate\", \"Rev Animated\", \"Robo-Diffusion\", \"SD-Silicon\", \"SDXL 1.0\", \"Sci-Fi Diffusion\", \"Seek.art MEGA\", \"Something\", \"Stable Cascade 1.0\", \"SwamPonyXL\", \"SweetBoys 2D\", \"TUNIX Pony\", \"ToonYou\", \"Trinart Characters\", \"UMI Olympus\", \"URPM\", \"Uhmami\", \"Ultraspice\", \"Unstable Diffusers XL\", \"Unstable Ink Dream\", \"Vector Art\", \"VinteProtogenMix\", \"WAI-ANI-NSFW-PONYXL\", \"WAI-CUTE Pony\", \"Western Animation Diffusion\", \"White Pony Diffusion 4\", \"Woop-Woop Photo\", \"Yiffy\", \"Zeipher Female Model\", \"iCoMix Inpainting\", \"iCoMix\", \"majicMIX realistic\", \"stable_diffusion\", \"stable_diffusion_2.1\", \"stable_diffusion_inpainting\", \"vectorartz\", \"waifu_diffusion\",\n"
          ]
        }
      ],
      "source": [
        "# @title ## Only to obtain the models names from the horde. If you want it, tick the checkbox here and run this cell. It does nothing for the worker, it will simply print a list of all the models (Outdated, pending){ display-mode: \"form\" }\n",
        "get_models = True # @param {type:\"boolean\"}\n",
        "\n",
        "if (get_models):\n",
        "\n",
        "  !wget -q -O /content/stable_diffusion.json https://raw.githubusercontent.com/Haidra-Org/AI-Horde-image-model-reference/main/stable_diffusion.json\n",
        "\n",
        "  with open(\"/content/stable_diffusion.json\", 'r') as file:\n",
        "      lines = file.readlines()\n",
        "\n",
        "  delete_name = '        \"name\": '\n",
        "  delete_enter = '\\n'\n",
        "  model_list = []\n",
        "\n",
        "  for i, line in enumerate(lines):\n",
        "      if delete_name in line:\n",
        "          #print(f\"{line.replace(delete_name, '').replace(delete_enter,'')}\")\n",
        "          #model_list.append = [f\"{line.replace(delete_name, '').replace(delete_enter,'')}\"]\n",
        "          model_list.append(line.replace(delete_name, '').replace(delete_enter,''))\n",
        "\n",
        "  model_list.sort()  # Sort the model_list in alphabetical order\n",
        "\n",
        "  #print(model_list)\n",
        "  print(' '.join(model_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqp_SIkg1cB2"
      },
      "outputs": [],
      "source": [
        "# @title # Simple Timer AND Clearscreen functions { display-mode: \"form\" }\n",
        "from IPython.display import Javascript\n",
        "\n",
        "# JavaScript function to clearscreen\n",
        "js_code = \"\"\"\n",
        "function clearScreen() {\n",
        "  document.body.innerHTML = \"\";\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# JavaScript functions to show timer\n",
        "js_code_2 = \"\"\"let startTime = new Date().getTime(); // Variable to store the start time\n",
        "\n",
        "function formatTime(seconds) {\n",
        "  const hours = Math.floor(seconds / 3600);\n",
        "  const minutes = Math.floor((seconds % 3600) / 60);\n",
        "  const remainingSeconds = seconds % 60;\n",
        "  return `${hours} hours, ${minutes} minutes, ${remainingSeconds} seconds`;\n",
        "}\n",
        "\n",
        "function updateTime() {\n",
        "  const currentTime = new Date().getTime();\n",
        "  const elapsedSeconds = Math.floor((currentTime - startTime) / 1000);\n",
        "  const formattedTime = formatTime(elapsedSeconds);\n",
        "  document.body.innerHTML = formattedTime;\n",
        "}\"\"\"\n",
        "\n",
        "# Set the interval for the function to run\n",
        "interval = \"1000\"\n",
        "\n",
        "# Display the JavaScript code in the cell\n",
        "display(Javascript(js_code_2 + f\"setInterval(updateTime, {interval})\"))\n",
        "\n",
        "def python_clearscreen_now():\n",
        "    display(Javascript(js_code + \"clearScreen()\"))\n",
        "\n",
        "def python_clearscreen_interval(interval):\n",
        "    display(Javascript(js_code + f\"setInterval(clearScreen, {interval})\"))\n",
        "\n",
        "\n",
        "\n",
        "# Function to clear outputs using Python's threads\n",
        "\n",
        "import threading\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def clear_output_periodically(interval):\n",
        "  \"\"\"\n",
        "  Clears the output cell periodically until the stop_thread flag is set.\n",
        "\n",
        "  Args:\n",
        "    interval: The interval in seconds between clearing the output.\n",
        "  \"\"\"\n",
        "  global stop_thread\n",
        "  while not stop_thread:\n",
        "    clear_output(wait=True)\n",
        "    time.sleep(interval)\n",
        "\n",
        "stop_thread = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T23:06:35.113455Z",
          "iopub.status.busy": "2023-10-20T23:06:35.112701Z"
        },
        "id": "qHYIcsqJ1xPs",
        "scrolled": true,
        "trusted": true,
        "outputId": "1283b543-a5d2-401b-bb11-7b63455f2a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model not supported by the Horde (non-Customizer Role)\n",
            "Model: AnyLoRA - Checkpoint, Horde Model: Dreamshaper, format: safetensors\n",
            "Running: ['Dreamshaper']\n",
            "bridgeData.yaml file not found. Proceed to install the worker.\n"
          ]
        }
      ],
      "source": [
        "# @title 0.- This cell will set the variables and rerun the worker if you stopped it, but only if everything else was installed already { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "\n",
        "#### For now, THESE are the only variables that we care about\n",
        "worker_name = \"Celesta2\" #@param {type:\"string\"}\n",
        "api_key = \"j3hxJgo8B8T6xYrNtC79HQ\" #@param {type:\"string\"}\n",
        "civitai_token = \"cae554bcc138d97a9323856c2dee1158\" #@param {type:\"string\"}\n",
        "max_power = \"32\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "selected_models = []\n",
        "#@markdown  ### Select what model(s) to host\n",
        "#@markdown  Recommended models, (bypasses the \"all models\" selector below when set)\n",
        "recommended_model1 = \"Anything Diffusion\" # @param [\"None\", \"ICBINP - I Can't Believe It's Not Photography\", \"Anything Diffusion\", \"Deliberate\", \"Dreamshaper\", \"BB95 Furry Mix\", \"Hentai Diffusion\", \"Rev Animated\", \"AlbedoBase XL (SDXL)\", \"Fustercluck\", \"ICBINP XL\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Juggernaut XL\", \"Pony Diffusion XL\", \"DreamShaper XL\", \"Cheyenne\", \"Unstable Diffusers XL\", \"Stable Cascade 1.0\"]\n",
        "recommended_model2 = \"Hentai Diffusion\" # @param [\"None\", \"ICBINP - I Can't Believe It's Not Photography\", \"Anything Diffusion\", \"Deliberate\", \"Dreamshaper\", \"BB95 Furry Mix\", \"Hentai Diffusion\", \"Rev Animated\", \"AlbedoBase XL (SDXL)\", \"Fustercluck\", \"ICBINP XL\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Juggernaut XL\", \"Pony Diffusion XL\", \"DreamShaper XL\", \"Cheyenne\", \"Unstable Diffusers XL\", \"Stable Cascade 1.0\"]\n",
        "\n",
        "#@markdown List of all models\n",
        "model1 = \"Grapefruit Hentai\" # @param [\"3DKX\", \"526Mix-Animated\", \"A-Zovya RPG Inpainting\", \"ACertainThing\", \"AIO Pixel Art\", \"Abyss OrangeMix\", \"AbyssOrangeMix-AfterDark\", \"AlbedoBase XL (SDXL)\", \"Analog Diffusion\", \"Analog Madness\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Anime Pencil Diffusion\", \"AnyLoRA\", \"Anygen\", \"Anything Diffusion Inpainting\", \"Anything Diffusion\", \"Anything v3\", \"Anything v5\", \"App Icon Diffusion\", \"Art Of Mtg\", \"Aurora\", \"BB95 Furry Mix\", \"BPModel\", \"BRA\", \"Babes\", \"BweshMix\", \"CamelliaMix 2.5D\", \"Cetus-Mix\", \"Char\", \"CharHelper\", \"Cheese Daddys Landscape Mix\", \"Cheyenne\", \"ChilloutMix\", \"ChromaV5\", \"Classic Animation Diffusion\", \"Colorful\", \"Comic-Diffusion\", \"Counterfeit\", \"CyberRealistic\", \"CyriousMix\", \"DGSpitzer Art Diffusion\", \"Dan Mumford Style\", \"Dark Sushi Mix\", \"Dark Victorian Diffusion\", \"Deliberate 3.0\", \"Deliberate Inpainting\", \"Deliberate\", \"Disco Elysium\", \"Disney Pixar Cartoon Type A\", \"DnD Item\", \"DnD Map Generator\", \"Double Exposure Diffusion\", \"DreamLikeSamKuvshinov\", \"DreamShaper Inpainting\", \"DreamShaper XL\", \"Dreamlike Diffusion\", \"Dreamlike Photoreal\", \"Dreamshaper\", \"DucHaiten Classic Anime\", \"DucHaiten\", \"Dungeons and Diffusion\", \"Dungeons n Waifus\", \"Edge Of Realism\", \"Eimis Anime Diffusion\", \"Elldreth's Lucid Mix\", \"Elysium Anime\", \"Epic Diffusion Inpainting\", \"Epic Diffusion\", \"Ether Real Mix\", \"ExpMix Line\", \"Experience\", \"FaeTastic\", \"Fantasy Card Diffusion\", \"Fluffusion\", \"Funko Diffusion\", \"Furry Epoch\", \"Fustercluck\", \"GTA5 Artwork Diffusion\", \"Galena Redux\", \"Ghibli Diffusion\", \"GhostMix\", \"GorynichMix\", \"Grapefruit Hentai\", \"Graphic-Art\", \"GuFeng\", \"GuoFeng\", \"HASDX\", \"HRL\", \"Hassaku\", \"Hassanblend\", \"Healy's Anime Blend\", \"Henmix Real\", \"Hentai Diffusion\", \"ICBINP - I Can't Believe It's Not Photography\", \"ICBINP XL\", \"Illuminati Diffusion\", \"Inkpunk Diffusion\", \"JWST Deep Space Diffusion\", \"Jim Eidomode\", \"JoMad Diffusion\", \"Juggernaut XL\", \"Kenshi\", \"Laolei New Berry Protogen Mix\", \"Lawlas's yiff mix\", \"Liberty\", \"Lyriel\", \"Mega Merge Diffusion\", \"MeinaMix\", \"Microcritters\", \"Microworlds\", \"Midjourney PaintArt\", \"Mistoon Amethyst\", \"ModernArt Diffusion\", \"Moedel\", \"MoistMix\", \"MoonMix Fantasy\", \"Movie Diffusion\", \"Neurogen\", \"NeverEnding Dream\", \"Nitro Diffusion\", \"OpenJourney Diffusion\", \"Openniji\", \"PFG\", \"PPP\", \"Papercut Diffusion\", \"Pastel Mix\", \"Perfect World\", \"Poison\", \"Pokemon3D\", \"Pony Diffusion XL\", \"PortraitPlus\", \"Pretty 2.5D\", \"Project Unreal Engine 5\", \"ProtoGen\", \"Protogen Anime\", \"Protogen Infinity\", \"Pulp Vector Art\", \"RPG\", \"Ranma Diffusion\", \"Real Dos Mix\", \"RealBiter\", \"Realisian\", \"Realism Engine\", \"Realistic Vision Inpainting\", \"Realistic Vision\", \"Reliberate\", \"Rev Animated\", \"Robo-Diffusion\", \"SD-Silicon\", \"SDXL 1.0\", \"Samaritan 3d Cartoon\", \"Sci-Fi Diffusion\", \"Seek.art MEGA\", \"Something\", \"Stable Cascade 1.0\", \"SweetBoys 2D\", \"ToonYou\", \"Trinart Characters\", \"Tron Legacy Diffusion\", \"UMI Olympus\", \"URPM\", \"Uhmami\", \"Ultraskin\", \"Unstable Diffusers XL\", \"Unstable Ink Dream\", \"Vector Art\", \"VinteProtogenMix\", \"Western Animation Diffusion\", \"Woop-Woop Photo\", \"Yiffy\", \"Zack3D\", \"Zeipher Female Model\", \"iCoMix Inpainting\", \"iCoMix\", \"majicMIX realistic\", \"stable_diffusion\", \"stable_diffusion_2.1\", \"stable_diffusion_inpainting\", \"vectorartz\", \"waifu_diffusion\"]\n",
        "model2 = \"Anime Illust Diffusion XL\" # @param [\"None\", \"3DKX\", \"526Mix-Animated\", \"A-Zovya RPG Inpainting\", \"ACertainThing\", \"AIO Pixel Art\", \"Abyss OrangeMix\", \"AbyssOrangeMix-AfterDark\", \"AlbedoBase XL (SDXL)\", \"Analog Diffusion\", \"Analog Madness\", \"Animagine XL\", \"Anime Illust Diffusion XL\", \"Anime Pencil Diffusion\", \"AnyLoRA\", \"Anygen\", \"Anything Diffusion Inpainting\", \"Anything Diffusion\", \"Anything v3\", \"Anything v5\", \"App Icon Diffusion\", \"Art Of Mtg\", \"Aurora\", \"BB95 Furry Mix\", \"BPModel\", \"BRA\", \"Babes\", \"BweshMix\", \"CamelliaMix 2.5D\", \"Cetus-Mix\", \"Char\", \"CharHelper\", \"Cheese Daddys Landscape Mix\", \"Cheyenne\", \"ChilloutMix\", \"ChromaV5\", \"Classic Animation Diffusion\", \"Colorful\", \"Comic-Diffusion\", \"Counterfeit\", \"CyberRealistic\", \"CyriousMix\", \"DGSpitzer Art Diffusion\", \"Dan Mumford Style\", \"Dark Sushi Mix\", \"Dark Victorian Diffusion\", \"Deliberate 3.0\", \"Deliberate Inpainting\", \"Deliberate\", \"Disco Elysium\", \"Disney Pixar Cartoon Type A\", \"DnD Item\", \"DnD Map Generator\", \"Double Exposure Diffusion\", \"DreamLikeSamKuvshinov\", \"DreamShaper Inpainting\", \"DreamShaper XL\", \"Dreamlike Diffusion\", \"Dreamlike Photoreal\", \"Dreamshaper\", \"DucHaiten Classic Anime\", \"DucHaiten\", \"Dungeons and Diffusion\", \"Dungeons n Waifus\", \"Edge Of Realism\", \"Eimis Anime Diffusion\", \"Elldreth's Lucid Mix\", \"Elysium Anime\", \"Epic Diffusion Inpainting\", \"Epic Diffusion\", \"Ether Real Mix\", \"ExpMix Line\", \"Experience\", \"FaeTastic\", \"Fantasy Card Diffusion\", \"Fluffusion\", \"Funko Diffusion\", \"Furry Epoch\", \"Fustercluck\", \"GTA5 Artwork Diffusion\", \"Galena Redux\", \"Ghibli Diffusion\", \"GhostMix\", \"GorynichMix\", \"Grapefruit Hentai\", \"Graphic-Art\", \"GuFeng\", \"GuoFeng\", \"HASDX\", \"HRL\", \"Hassaku\", \"Hassanblend\", \"Healy's Anime Blend\", \"Henmix Real\", \"Hentai Diffusion\", \"ICBINP - I Can't Believe It's Not Photography\", \"ICBINP XL\", \"Illuminati Diffusion\", \"Inkpunk Diffusion\", \"JWST Deep Space Diffusion\", \"Jim Eidomode\", \"JoMad Diffusion\", \"Juggernaut XL\", \"Kenshi\", \"Laolei New Berry Protogen Mix\", \"Lawlas's yiff mix\", \"Liberty\", \"Lyriel\", \"Mega Merge Diffusion\", \"MeinaMix\", \"Microcritters\", \"Microworlds\", \"Midjourney PaintArt\", \"Mistoon Amethyst\", \"ModernArt Diffusion\", \"Moedel\", \"MoistMix\", \"MoonMix Fantasy\", \"Movie Diffusion\", \"Neurogen\", \"NeverEnding Dream\", \"Nitro Diffusion\", \"OpenJourney Diffusion\", \"Openniji\", \"PFG\", \"PPP\", \"Papercut Diffusion\", \"Pastel Mix\", \"Perfect World\", \"Poison\", \"Pokemon3D\", \"Pony Diffusion XL\", \"PortraitPlus\", \"Pretty 2.5D\", \"Project Unreal Engine 5\", \"ProtoGen\", \"Protogen Anime\", \"Protogen Infinity\", \"Pulp Vector Art\", \"RPG\", \"Ranma Diffusion\", \"Real Dos Mix\", \"RealBiter\", \"Realisian\", \"Realism Engine\", \"Realistic Vision Inpainting\", \"Realistic Vision\", \"Reliberate\", \"Rev Animated\", \"Robo-Diffusion\", \"SD-Silicon\", \"SDXL 1.0\", \"Samaritan 3d Cartoon\", \"Sci-Fi Diffusion\", \"Seek.art MEGA\", \"Something\", \"Stable Cascade 1.0\", \"SweetBoys 2D\", \"ToonYou\", \"Trinart Characters\", \"Tron Legacy Diffusion\", \"UMI Olympus\", \"URPM\", \"Uhmami\", \"Ultraskin\", \"Unstable Diffusers XL\", \"Unstable Ink Dream\", \"Vector Art\", \"VinteProtogenMix\", \"Western Animation Diffusion\", \"Woop-Woop Photo\", \"Yiffy\", \"Zack3D\", \"Zeipher Female Model\", \"iCoMix Inpainting\", \"iCoMix\", \"majicMIX realistic\", \"stable_diffusion\", \"stable_diffusion_2.1\", \"stable_diffusion_inpainting\", \"vectorartz\", \"waifu_diffusion\"]\n",
        "#@markdown Because Colab has low RAM, it is not recommended to run more than 1 model or any of the SDXL models, but you can certainly try (if you do, you might want to set queue size to 0, it will certainly let you run any number of SD 1.5 models, provided you have the disk space for them and you don't mind the long download time and the loading times between models when the worker is actually running)\n",
        "\n",
        "if (recommended_model1 != \"None\"):\n",
        "    selected_models.append(recommended_model1)\n",
        "else:\n",
        "    selected_models.append(model1)\n",
        "\n",
        "if (recommended_model2 != \"None\"):\n",
        "    selected_models.append(recommended_model2)\n",
        "else:\n",
        "    if (model2 != \"None\"):\n",
        "        selected_models.append(model2)\n",
        "\n",
        "\n",
        "# I'm leaving this next line in case you want to set more than 2 models or whatever weird thing you want\n",
        "# simply uncomment it and it will ignore the selections above.\n",
        "# It is set the models I run when I set it to more than 1, but you can change it to whatever you want\n",
        "#selected_models = [\"ICBINP - I Can't Believe It's Not Photography\", \"Deliberate\", \"Anything Diffusion\", \"Dreamshaper\"]\n",
        "\n",
        "###\n",
        "#@markdown ---\n",
        "#@markdown ### Models not supported by the Horde\n",
        "\n",
        "outside_model = True #@param {type:\"boolean\"}\n",
        "outside_model_name = \"AnyLoRA - Checkpoint\" #@param {type:\"string\"}\n",
        "model_file_name = \"anyloraCheckpoint_bakedvaeBlessedFp16\" #@param {type:\"string\"}\n",
        "baseline = \"SD 1.5\" # @param [\"SD 1.5\", \"SD XL\"]\n",
        "outside_model_download_url = \"https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/53515/model/anyloraBakedvaeFp16.SCrY.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22anyloraCheckpoint_bakedvaeBlessedFp16.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20241120/us-east-1/s3/aws4_request&X-Amz-Date=20241120T183122Z&X-Amz-SignedHeaders=host&X-Amz-Signature=2720bd150e6b8ad2a21460ef53e82513f3362e22c34949a1468b6d4cdb4df570\" #@param {type:\"string\"}\n",
        "#@markdown ##### - To use unsupported/deprecated models (Segmind, Van Gogh Diffusion, etc)\n",
        "#@markdown ##### - For personal use, not to serve these models to the public\n",
        "#@markdown ##### - The worker is configured to activate Maintenance Mode when set to use outside models, this is to protect the owner\n",
        "#@markdown ##### - For this to work, all fields above must be filled:\n",
        "#@markdown ##### -1- outside_model, switch/toggle, a necessary check\n",
        "#@markdown ##### -2- outside_model_name, only for you to know what model is being served\n",
        "#@markdown ##### -3- model_file_name, the worker needs at least a part of the file's name to function\n",
        "#@markdown ##### -4- baseline, Stable Diffusion 1.5 or XL, necessary\n",
        "#@markdown ##### -4- outside_model_download_url, the download URL for the model you want to use. With civitai, check under \"1-2-3-x file\" and copy the download link there\n",
        "\n",
        "if(\"PickleTensor\" in outside_model_download_url or \".ckpt\" in outside_model_download_url):\n",
        "    file_extension = \".ckpt\"\n",
        "if(\"SafeTensor\" in outside_model_download_url or \".safetensors\" in outside_model_download_url):\n",
        "    file_extension = \".safetensors\"\n",
        "\n",
        "civitai = \"civitai.com/api/download/models\"\n",
        "if (civitai in outside_model_download_url):\n",
        "    outside_model_download_url = outside_model_download_url.split(\"?\")[0] + \"?token=\" + civitai_token\n",
        "\n",
        "new_mod15_ckpt = {\n",
        "    'model_name': \"Anything Diffusion\",\n",
        "    'file_name': \"Anything-Diffusion.ckpt\",\n",
        "    'sha256': \"633c153d96230355efb4230da6ae2e3ba85b084b93c89eb88cb1118d6cc06cef *Anything-Diffusion.sha256\",\n",
        "    'sha_name': \"Anything-Diffusion.sha256\"\n",
        "}\n",
        "new_mod15_safe = {\n",
        "    'model_name': \"Dreamshaper\",\n",
        "    'file_name': \"Dreamshaper.safetensors\",\n",
        "    'sha256': \"879db523c30d3b9017143d56705015e15a2cb5628762c11d086fed9538abd7fd *Dreamshaper.sha256\",\n",
        "    'sha_name': \"Dreamshaper.sha256\"\n",
        "}\n",
        "new_modxl_safe = {\n",
        "    'model_name': \"AlbedoBase XL (SDXL)\",\n",
        "    'file_name': \"albedo_base_xl.safetensors\",\n",
        "    'sha256': \"1718B5BB2DA1EF4815FEE8AF8A7FC2FA8AB8F467B279EDED4D991EA0CCE59A6D *albedo_base_xl.sha256\",\n",
        "    'sha_name': \"albedo_base_xl.sha256\"\n",
        "}\n",
        "if (baseline == \"SD XL\"):\n",
        "    new_mod = new_modxl_safe\n",
        "if (baseline == \"SD 1.5\"):\n",
        "    if(file_extension == \".ckpt\"):\n",
        "        new_mod = new_mod15_ckpt\n",
        "    if(file_extension == \".safetensors\"):\n",
        "        new_mod = new_mod15_safe\n",
        "\n",
        "if (outside_model and outside_model_name and outside_model_download_url):\n",
        "    selected_models = []\n",
        "    selected_models.append(new_mod['model_name'])\n",
        "    print (\"Running model not supported by the Horde (non-Customizer Role)\")\n",
        "    print (f'''Model: {outside_model_name:}, Horde Model: {new_mod['model_name']}, format: {new_mod['file_name'].split(\".\")[1]}''')\n",
        "# To actually enable models not supported by the Horde\n",
        "\n",
        "\n",
        "\n",
        "models_to_load = list(set(selected_models))\n",
        "print(f'Running: {models_to_load}')\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "allow_img2img = True #@param {type:\"boolean\"}\n",
        "allow_painting = True #@param {type:\"boolean\"}\n",
        "allow_lora = False #@param {type:\"boolean\"}\n",
        "allow_controlnet = False #@param {type:\"boolean\"}\n",
        "allow_post_processing = True #@param {type:\"boolean\"}\n",
        "#@markdown  ### I recommend you don't change these next 2 settings if you have no idea what you are doing\n",
        "queue_size = \"2\" # @param [0, 1, 2, 3, 4, 5]\n",
        "max_threads = \"1\" # @param [1, 2, 3]\n",
        "max_batch = \"5\" # @param [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "#@markdown ---\n",
        "\n",
        "safety_on_gpu = True\n",
        "nsfw = True\n",
        "censor_nsfw = False\n",
        "\n",
        "##############################\n",
        "#@markdown ## OPTIONAL, enabled by default\n",
        "#@markdown Disable default loras (reason: they are both obsolete and outdated)\n",
        "edit_lora_py_change_default_loras_bool = True #@param {type:\"boolean\"}\n",
        "#@markdown Increase Lora size limit to 1GB (reason: good donwload speed and storage capacity)\n",
        "edit_lora_py_increase_lora_size_limit_bool = True #@param {type:\"boolean\"}\n",
        "\n",
        "#markdown ## HIGHLY EXPERIMENTAL - OPTIONAL, disabled by default ####\n",
        "#markdown ##### Colab exclusive, for now, inject loras and textual inversions through prompt so they can be used in similar fashion to A1111\n",
        "#markdown ##### For loras: <lora:civitaiID or name:lora_strength:lora_clip:is_version, Anything you want here, to identify this lora>\n",
        "#markdown ##### Explaining is_version: 1--->True, 0--->False; If 0, use as always, put the civitAI ID and done; If 1, then you need the modelVersion (found in the URL on civitAI) instead of civitAI ID\n",
        "#markdown ##### Example with Add more details lora: \"<lora:82098:0.4:1.0:0, Add More Details>\": \"82098\", civitaiID; \"0.4\", lora model strength; \"1.0\", lora clip Strength; \"0\", is_version (0 means False);\n",
        "#markdown ##### For textual inversions: (embedding:civitaiID:ti_strength)\n",
        "#experimental = False #@param {type:\"boolean\"}\n",
        "#markdown ##### why? because some front-ends don't support loras/tis, so instead we let the worker handle that part and now EVERYONE can use them,\n",
        "#markdown ##### no matter what client they use to access the horde\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#markdown #### Obsolete while I set it up.\n",
        "beta_switch = False\n",
        "#markdown #### (RECOMMENDED) Enable this one to use the last stable version of the worker confirmed to work.\n",
        "#markdown #### IMPORTANT - If neither switch is set, it will download the current worker\n",
        "last_tested = False\n",
        "#markdown #### The maximum number of jobs the worker can do in a batch. I can confirm that up to 5 works, but there are very few batch requests for now so I don't yet know the best value for this.\n",
        "#markdown #### \"The horde will not give your max_batch at your max resolution, in order to avoid running out of VRAM. The Horde will assume you can fulfil your max batch at HALF your max resolution\"\n",
        "#markdown ---\n",
        "\n",
        "####For right now, THESE are the only variables that we care about\n",
        "\n",
        "\n",
        "horde_url = \"https://aihorde.net\"\n",
        "dynamic_models = False\n",
        "models_to_skip = [\"stable_diffusion_inpainting\", \"stable_diffusion_2.1\",  \"stable_diffusion_2.0\"]\n",
        "\n",
        "priority_usernames = []\n",
        "blacklist = []\n",
        "censorlist = []\n",
        "\n",
        "allow_unsafe_ip = True\n",
        "number_of_dynamic_models = 0\n",
        "max_models_to_download = 10\n",
        "forms = [\"caption\",\"nsfw\",\"interrogation\",\"post-process\"]\n",
        "\n",
        "\n",
        "current_path = \"/content/\"\n",
        "worker_path = current_path + \"horde-worker-reGen/\"\n",
        "bridgeData_file = worker_path + \"bridgeData.yaml\"\n",
        "notebook_version = \"23-05-2024\"\n",
        "\n",
        "#@markdown To reduce the level of verbosity/show shorter logs (Colab uses more and more of your PC RAM as the logs grow longer, but this will help with that)\n",
        "Short_Logs = False #@param {type:\"boolean\"}\n",
        "shorter_logs = Short_Logs\n",
        "#@markdown You can set here how often to clear logs (output only), in seconds. If left empty, logs will not be cleared\n",
        "interval = \"120\" #@param [\"\", 20, 30, 60, 120, 300, 1800, 3600]\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown To set maintenance mode ON/OFF on rerunning.\n",
        "Maintenance_Mode = False # @param {type:\"boolean\"}\n",
        "#@markdown Will be set to ON if running Outside Models. You need to keep your worker in Maintenance Mode with models not supported by the Horde, otherwise your worker will take people's request as normal and someone WILL report your worker for not giving the expected results.\n",
        "\n",
        "if not os.path.exists(bridgeData_file):\n",
        "    print (\"bridgeData.yaml file not found. Proceed to install the worker.\")\n",
        "else:\n",
        "    print (\"bridgeData.yaml file found. Recreating bridgeData.yaml and restarting the worker.\")\n",
        "    create_yaml()\n",
        "\n",
        "    download_models_aria2c()\n",
        "\n",
        "    if (Maintenance_Mode):\n",
        "        Maintenance_Mode = True\n",
        "    else:\n",
        "        if (outside_model and outside_model_name and outside_model_download_url):\n",
        "            Maintenance_Mode = True\n",
        "        else:\n",
        "            Maintenance_Mode = False\n",
        "    Set_Maintenance_Mode_function(Maintenance_Mode)\n",
        "\n",
        "    !cd /content\n",
        "    !source ../regen/bin/activate;python download_models.py\n",
        "    !cd /content\n",
        "\n",
        "    # Stop any reamining threads, maybe\n",
        "    stop_thread = True\n",
        "    # Start the thread\n",
        "    stop_thread = False\n",
        "    try:\n",
        "        threading.Thread(target=clear_output_periodically, args=(int(interval),)).start()\n",
        "        print(f\"Logs (output only) will be cleared every {int(interval)} seconds\")\n",
        "    except:\n",
        "        print(\"Logs will not be deleted\")\n",
        "\n",
        "    if (Short_Logs):\n",
        "        !source ../regen/bin/activate;python run_worker.py -vv\n",
        "    else:\n",
        "        !source ../regen/bin/activate;python run_worker.py\n",
        "\n",
        "# Stop any reamining threads, maybe\n",
        "stop_thread = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lfZ8JE4g1cB3",
        "outputId": "ed76142a-25dd-4f99-f7cd-32a4e932bbb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No worker with the name: Celesta2, can't change Maintenance Mode. A new worker will be created with that name.\n"
          ]
        }
      ],
      "source": [
        "# @title Get the Worker OUT of Maintenance Mode { display-mode: \"form\" }\n",
        "# This cell is to get the worker out of maintenance before starting, since some people don't know how or where to do it\n",
        "# Should be alright to do it here since most errors for Colab workers are not the owner's fault\n",
        "\n",
        "import subprocess\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "\n",
        "def Set_Maintenance_Mode_function(Maintenance_Mode):\n",
        "\n",
        "    i = False #Worker does not match/exist flag\n",
        "\n",
        "    command_find_user = f'''curl -X 'GET' \\\n",
        "              '{horde_url}/api/v2/find_user' \\\n",
        "              -H 'accept: application/json' \\\n",
        "              -H 'apikey: {api_key}' \\\n",
        "              -H 'Client-Agent: unknown:0:unknown'\n",
        "            '''\n",
        "\n",
        "    find_user_response = subprocess.check_output(command_find_user, shell=True).decode('utf-8')\n",
        "    data_api_key = json.loads(find_user_response)\n",
        "\n",
        "    if not (\"message\" in find_user_response):\n",
        "        for worker_id in data_api_key['worker_ids']:\n",
        "            command_find_worker = f'''curl -X 'GET' \\\n",
        "                      '{horde_url}/api/v2/workers/{worker_id}' \\\n",
        "                      -H 'accept: application/json' \\\n",
        "                      -H 'apikey: {api_key}' \\\n",
        "                      -H 'Client-Agent: unknown:0:unknown'\n",
        "                    '''\n",
        "            find_worker_response = subprocess.check_output(command_find_worker, shell=True).decode('utf-8')\n",
        "            data_worker = json.loads(find_worker_response)\n",
        "            if (worker_name == data_worker['name']):\n",
        "                print(f'''Worker name: {worker_name}, Worker ID: {worker_id}''')\n",
        "                i = True\n",
        "                if (Maintenance_Mode):\n",
        "                  set_maintenance_mode = \"true\"\n",
        "                else:\n",
        "                  set_maintenance_mode = \"false\"\n",
        "                command_maintenance_mode = f'''curl -X 'PUT' \\\n",
        "                  '{horde_url}/api/v2/workers/{worker_id}' \\\n",
        "                  -H 'accept: application/json' \\\n",
        "                  -H 'apikey: {api_key}' \\\n",
        "                  -H 'Client-Agent: unknown:0:unknown' \\\n",
        "                  -H 'Content-Type: application/json' \\\n",
        "                  -d'''+ r''' '{\n",
        "                  \"maintenance\":''' + f''' {set_maintenance_mode}\n",
        "                ''' + r'''}'\n",
        "                '''\n",
        "                maintenance_mode_response = subprocess.check_output(command_maintenance_mode, shell=True).decode('utf-8')\n",
        "                print(maintenance_mode_response)\n",
        "        if not i:\n",
        "          print(f'''No worker with the name: {worker_name}, can't change Maintenance Mode. A new worker will be created with that name.''')\n",
        "          worker_id = 0\n",
        "    else:\n",
        "        print(f'''The API key \"{api_key}\" does not exist''')\n",
        "\n",
        "Maintenance_Mode = False\n",
        "Set_Maintenance_Mode_function(Maintenance_Mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cVecpjOM1xPu",
        "trusted": true,
        "outputId": "03c08bfa-7c31-4c04-a1e9-8631196943d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,148 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,223 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,487 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.2 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,732 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,318 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [52.2 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,512 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,408 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,449 kB]\n",
            "Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,613 kB]\n",
            "Fetched 27.4 MB in 5s (5,444 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib python3-pip-whl\n",
            "  python3-setuptools-whl python3.10 python3.10-dev python3.10-minimal\n",
            "Suggested packages:\n",
            "  python3.10-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "The following packages will be upgraded:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib python3.10\n",
            "  python3.10-dev python3.10-minimal\n",
            "7 upgraded, 3 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 15.1 MB of archives.\n",
            "After this operation, 2,914 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.7 [508 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.7 [4,762 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.7 [1,949 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.7 [509 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.7 [1,850 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.7 [2,279 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.7 [814 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.5 [1,680 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.2 [788 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.7 [5,718 B]\n",
            "Fetched 15.1 MB in 3s (4,426 kB/s)\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python3.10-dev_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking python3.10-dev (3.10.12-1~22.04.7) over (3.10.12-1~22.04.6) ...\n",
            "Preparing to unpack .../1-libpython3.10-dev_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.7) over (3.10.12-1~22.04.6) ...\n",
            "Preparing to unpack .../2-libpython3.10_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking libpython3.10:amd64 (3.10.12-1~22.04.7) over (3.10.12-1~22.04.6) ...\n",
            "Preparing to unpack .../3-python3.10_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking python3.10 (3.10.12-1~22.04.7) over (3.10.12-1~22.04.6) ...\n",
            "Preparing to unpack .../4-libpython3.10-stdlib_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.7) over (3.10.12-1~22.04.6) ...\n",
            "Preparing to unpack .../5-python3.10-minimal_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking python3.10-minimal (3.10.12-1~22.04.7) over (3.10.12-1~22.04.6) ...\n",
            "Preparing to unpack .../6-libpython3.10-minimal_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.7) over (3.10.12-1~22.04.6) ...\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "Preparing to unpack .../7-python3-pip-whl_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../8-python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../9-python3.10-venv_3.10.12-1~22.04.7_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.7) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.7) ...\n",
            "Setting up python3.10-minimal (3.10.12-1~22.04.7) ...\n",
            "Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.7) ...\n",
            "Setting up libpython3.10:amd64 (3.10.12-1~22.04.7) ...\n",
            "Setting up python3.10 (3.10.12-1~22.04.7) ...\n",
            "Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.7) ...\n",
            "Setting up python3.10-dev (3.10.12-1~22.04.7) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 1.- Virtual Environment  { display-mode: \"form\" }\n",
        "\n",
        "!apt-get update\n",
        "!apt install python3.10-venv\n",
        "!python -m venv regen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZzwQDVd_1xPu",
        "trusted": true,
        "outputId": "1c9ebb1c-d1e6-4a01-d80a-cdb132aabdfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'horde-worker-reGen': No such file or directory\n",
            "Horde Engine Line: horde_engine~=2.17.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 2.- Remove the worker if it exists, then, Clone the regen worker { display-mode: \"form\" }\n",
        "\n",
        "!cd /content;rm -r horde-worker-reGen\n",
        "\n",
        "if (beta_switch):\n",
        "    #!cd /content;git clone -b niter https://github.com/Haidra-Org/horde-worker-reGen.git > /dev/null 2>&1\n",
        "    ## Deleting the next part when beta_switch is ready, too lazy to figure it out\n",
        "    !cd /content;git clone https://github.com/Haidra-Org/horde-worker-reGen.git > /dev/null 2>&1\n",
        "    if (last_tested):\n",
        "        %cd /content/horde-worker-reGen\n",
        "        version = \"0776b3967d566ac3826a8c2083d0c315caaf26a1\"\n",
        "        !cd /content/horde-worker-reGen;git checkout version > /dev/null 2>&1\n",
        "        print (f'Worker Version (hash): {version}')\n",
        "        %cd /content\n",
        "else:\n",
        "    !cd /content;git clone https://github.com/Haidra-Org/horde-worker-reGen.git > /dev/null 2>&1\n",
        "    if (last_tested):\n",
        "        %cd /content/horde-worker-reGen\n",
        "        version = \"0776b3967d566ac3826a8c2083d0c315caaf26a1\"\n",
        "        !cd /content/horde-worker-reGen;git checkout version > /dev/null 2>&1\n",
        "        print (f'Worker Version (hash): {version}')\n",
        "        %cd /content\n",
        "\n",
        "# Necessary for edits, etc\n",
        "requirements_path = \"/content/horde-worker-reGen/requirements.txt\"\n",
        "horde_engine_version = \"fail\"\n",
        "# read the file\n",
        "with open(requirements_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "found_line_number = -1\n",
        "search_horde_engine_version = \"horde_engine\"\n",
        "for i, line in enumerate(lines):\n",
        "    if search_horde_engine_version in line:\n",
        "        horde_engine_version = line\n",
        "        break\n",
        "\n",
        "if (\"fail\" in horde_engine_version):\n",
        "    print (\"Could not find hordelib version in requirements.txt\")\n",
        "\n",
        "import re\n",
        "horde_engine_version_numeric_part = re.sub(r'^\\D*', '', horde_engine_version).rstrip()\n",
        "print (f'Horde Engine Line: {horde_engine_version}')\n",
        "horde_engine_version = horde_engine_version_numeric_part\n",
        "horde_engine_url = \"https://raw.githubusercontent.com/Haidra-Org/hordelib/v\" + horde_engine_version + \"/hordelib/\"\n",
        "horde_engine_path = \"/content/regen/lib/python3.10/site-packages/hordelib/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC4lce-51xPv",
        "scrolled": true,
        "trusted": true,
        "outputId": "af2f4ee0-2abc-4859-9f09-ee7770322f2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.5.0\n",
            "  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qrcode==7.4.2\n",
            "  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m46.2/46.2 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting horde_sdk~=0.15.1\n",
            "  Downloading horde_sdk-0.15.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m140.3/140.3 KB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting horde_safety~=0.2.3\n",
            "  Downloading horde_safety-0.2.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m50.3/50.3 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting horde_engine~=2.17.1\n",
            "  Downloading horde_engine-2.17.1-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting horde_model_reference>=0.9.1\n",
            "  Downloading horde_model_reference-0.9.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.8/56.8 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.8/117.8 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semver\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m72.5/72.5 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting pydantic>=2.9.2\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m434.9/434.9 KB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting StrEnum\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.5/62.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting babel\n",
            "  Downloading babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Collecting triton==3.1.0\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.13.1\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m133.3/133.3 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m179.6/179.6 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypng\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.1/58.1 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiodns\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Collecting pillow\n",
            "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting pydantic-core==2.23.4\n",
            "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clip-interrogator==0.6.0\n",
            "  Downloading clip_interrogator-0.6.0-py3-none-any.whl (787 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m787.8/787.8 KB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m235.5/235.5 KB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m333.2/333.2 KB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting open-clip-torch\n",
            "  Downloading open_clip_torch-2.29.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors\n",
            "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m435.0/435.0 KB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.27.1\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.3\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting clip-anytorch\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers>=0.25.0\n",
            "  Downloading diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mediapipe>=0.9.1.0\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m751.2/751.2 KB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rembg\n",
            "  Downloading rembg-2.0.60-py3-none-any.whl (39 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m207.3/207.3 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m899.4/899.4 KB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m266.3/266.3 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm==0.9.16\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m815.2/815.2 KB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-contrib-python\n",
            "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distro\n",
            "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.2/43.2 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spandrel-extra-arches\n",
            "  Downloading spandrel_extra_arches-0.2.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m86.3/86.3 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m287.3/287.3 KB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image\n",
            "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting spandrel\n",
            "  Downloading spandrel-0.4.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m297.5/297.5 KB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m53.8/53.8 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchsde\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.2/61.2 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m447.5/447.5 KB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m722.2/722.2 KB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Levenshtein==0.26.1\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m162.6/162.6 KB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.9.0\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m126.3/126.3 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Collecting jax\n",
            "  Downloading jax-0.4.35-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxlib\n",
            "  Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl (87.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m87.3/87.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=19.1.0\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m63.0/63.0 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<5,>=4.25.3\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m294.6/294.6 KB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Collecting absl-py\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycares>=4.0.0\n",
            "  Downloading pycares-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m288.7/288.7 KB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting propcache>=0.2.0\n",
            "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m208.9/208.9 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.17.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m319.2/319.2 KB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m44.8/44.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Collecting kornia-rs>=0.1.0\n",
            "  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m926.4/926.4 KB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities>=0.10.0\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Collecting pymatting\n",
            "  Downloading PyMatting-1.1.13-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pooch\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m64.6/64.6 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m88.5/88.5 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tifffile>=2022.8.12\n",
            "  Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m228.2/228.2 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazy-loader>=0.4\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Collecting imageio>=2.33\n",
            "  Downloading imageio-2.36.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m315.4/315.4 KB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trampoline>=0.1.2\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in ./regen/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning->horde_engine~=2.17.1->-r ./horde-worker-reGen/requirements.txt (line 8)) (59.6.0)\n",
            "Collecting cffi>=1.5.0\n",
            "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m446.2/446.2 KB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Collecting zipp>=3.20\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Collecting opt-einsum\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m71.9/71.9 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ml-dtypes>=0.4.0\n",
            "  Downloading ml_dtypes-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting referencing>=0.28.4\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Downloading rpds_py-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m360.8/360.8 KB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m229.9/229.9 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.55.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
            "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m106.9/106.9 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting platformdirs>=2.5.0\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Collecting numba!=0.49.0\n",
            "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycparser\n",
            "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.6/117.6 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.44,>=0.43.0dev0\n",
            "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n"
          ]
        }
      ],
      "source": [
        "# @title 3.- Install requirements { display-mode: \"form\" }\n",
        "\n",
        "!source regen/bin/activate;pip install -r .\\/horde-worker-reGen/requirements.txt\n",
        "\n",
        "# Fix for cuda 11.8 no longer required\n",
        "#!source regen/bin/activate;pip install -r .\\/horde-worker-reGen/requirements.118.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-I1XNxx1xPv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# @title 4.- Create .yaml config file { display-mode: \"form\" }\n",
        "\n",
        "import os\n",
        "\n",
        "%cd $worker_path\n",
        "print (\"Creating bridgeData.yaml file.\")\n",
        "\n",
        "def create_yaml():\n",
        "\n",
        "    from yaml import load, dump\n",
        "\n",
        "    def make_yaml_sublist(list_to_convert: list[str]):\n",
        "        sublist_yaml = dump(list_to_convert)\n",
        "        sublist_yaml = \"\\n\" + sublist_yaml\n",
        "        return sublist_yaml\n",
        "\n",
        "\n",
        "\n",
        "    data = f\"\"\"horde_url: \"{horde_url}\"\n",
        "api_key: \"{api_key}\"\n",
        "civitai_api_token: \"{civitai_token}\"\n",
        "priority_usernames: []\n",
        "max_threads: {max_threads}\n",
        "queue_size: {queue_size}\n",
        "max_batch: {max_batch}\n",
        "safety_on_gpu: {safety_on_gpu}\n",
        "require_upfront_kudos: false\n",
        "cycle_process_on_model_change: true\n",
        "dreamer_name: \"{worker_name}\"\n",
        "max_power: {max_power}\n",
        "nsfw: {nsfw.__str__().lower()}\n",
        "censor_nsfw: {censor_nsfw}\n",
        "blacklist: {blacklist}\n",
        "censorlist: {censorlist}\n",
        "allow_img2img: {allow_img2img.__str__().lower()}\n",
        "allow_painting: {allow_painting.__str__().lower()}\n",
        "allow_unsafe_ip: true\n",
        "allow_post_processing: {allow_post_processing.__str__().lower()}\n",
        "allow_controlnet: {allow_controlnet.__str__().lower()}\n",
        "allow_lora: {allow_lora.__str__().lower()}\n",
        "max_lora_cache_size: 20\n",
        "dynamic_models: false\n",
        "number_of_dynamic_models: 0\n",
        "max_models_to_download: 10\n",
        "stats_output_frequency: 30\n",
        "cache_home: \"./\"\n",
        "always_download: true\n",
        "temp_dir: \"./tmp\"\n",
        "disable_terminal_ui: True\n",
        "vram_to_leave_free: \"80%\"\n",
        "ram_to_leave_free: \"80%\"\n",
        "disable_disk_cache: false\n",
        "models_to_load: {make_yaml_sublist(models_to_load)}\n",
        "models_to_skip: {make_yaml_sublist(models_to_skip)}\n",
        "suppress_speed_warnings: false\n",
        "forms:\n",
        "- \"caption\"\n",
        "- \"nsfw\"\n",
        "- \"interrogation\"\n",
        "- \"post-process\"\n",
        "\"\"\"\n",
        "\n",
        "    with open(bridgeData_file, \"w\") as text_file:\n",
        "        text_file.write(data)\n",
        "\n",
        "    print (\"bridgeData.yaml file created.\")\n",
        "\n",
        "create_yaml()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFrhtj4-1cCG"
      },
      "outputs": [],
      "source": [
        "# @title Download models using aria2c { display-mode: \"form\" }\n",
        "\n",
        "model_reference = \"/content/stable_diffusion.json\"\n",
        "\n",
        "# create compvis folder\n",
        "!mkdir -p /content/horde-worker-reGen/compvis\n",
        "\n",
        "# download the model reference if necessary\n",
        "import os\n",
        "if os.path.exists(model_reference):\n",
        "    print(\"Model Reference exists.\")\n",
        "else:\n",
        "    print(\"Downloading Model Reference.\")\n",
        "    !wget https://raw.githubusercontent.com/Haidra-Org/AI-Horde-image-model-reference/main/stable_diffusion.json -O /content/stable_diffusion.json\n",
        "\n",
        "# install aria2c if necessary\n",
        "import subprocess\n",
        "try:\n",
        "    # Run the command\n",
        "    output = subprocess.check_output([\"which\", \"aria2c\"])\n",
        "    # unnecessary to do this next step, but whatever, I can use the output from above with this\n",
        "    output = output.decode(\"utf-8\")\n",
        "    print(\"aria2c is installed.\")\n",
        "except:\n",
        "    print(f\"Installing aria2c.\")\n",
        "    !apt-get install -y aria2\n",
        "\n",
        "\n",
        "# function to look in the model reference for the selected models\n",
        "import json\n",
        "def find_matching_entries(filename, key, value_list):\n",
        "    \"\"\"\n",
        "    Finds all entries in a JSON file that match a given key and value list.\n",
        "\n",
        "    Args:\n",
        "      filename: The path to the JSON file.\n",
        "      key: The key to search for.\n",
        "      value_list: A list of values to match.\n",
        "\n",
        "    Returns:\n",
        "      A list of entries that match the criteria.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    matching_entries = []\n",
        "    for entry in data.items():\n",
        "        #print(entry)\n",
        "        if entry[0] in value_list:\n",
        "            matching_entries.append(entry)\n",
        "\n",
        "    return matching_entries\n",
        "\n",
        "\n",
        "# function to download the models with aria2c\n",
        "def download_models_aria2c():\n",
        "\n",
        "    filename = model_reference\n",
        "    key = \"name\"\n",
        "    value_list = selected_models\n",
        "    # call the find function\n",
        "    matching_entries = find_matching_entries(filename, key, value_list)\n",
        "\n",
        "    # download the model(s) and create the hash file(s)\n",
        "    %cd $worker_path\n",
        "    for entry in matching_entries:\n",
        "        #download link\n",
        "        if (\"civitai\" in entry[1][\"config\"]['download'][0]['file_url']):\n",
        "            entry[1][\"config\"]['download'][0]['file_url'] = entry[1][\"config\"]['download'][0]['file_url'].split(\"?\")[0] + \"?token=\" + civitai_token\n",
        "        if (outside_model and outside_model_name and outside_model_download_url and entry[0] in mask['model_name']):\n",
        "            print(f\"Outside model:{outside_model_name}\")\n",
        "            download_link = outside_model_download_url\n",
        "        else:\n",
        "            download_link = entry[1][\"config\"]['download'][0]['file_url']\n",
        "        print(download_link)\n",
        "        # file name\n",
        "        file_name = entry[1][\"config\"]['download'][0]['file_name']\n",
        "        print(file_name)\n",
        "        file_path = \"compvis/\" + file_name\n",
        "        # sha256\n",
        "        sha_name = file_name.split(\".\")[0] + \".sha256\"\n",
        "        sha = entry[1][\"config\"]['files'][0]['sha256sum']\n",
        "        sha = sha + \" *\" + sha_name\n",
        "        sha_path = \"/content/horde-worker-reGen/compvis/\" + sha_name\n",
        "        print(sha)\n",
        "        # donwnload model and create sha file\n",
        "        !aria2c -c -x 16 -s 16 -p $download_link -o $file_path\n",
        "        !rm $sha_path\n",
        "        !echo {sha} > $sha_path\n",
        "\n",
        "download_models_aria2c()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GuwSZjY1cCH"
      },
      "outputs": [],
      "source": [
        "# @title ## Function: download file(s) { display-mode: \"form\" }\n",
        "\n",
        "# Simple download function with wget\n",
        "def download_file_wget(install_path, download_url):\n",
        "    !wget -O {install_path} {download_url}\n",
        "\n",
        "\n",
        "# define names, paths and urls for the files to download\n",
        "\n",
        "# horde engine files\n",
        "model_manager_folder = \"model_manager/\"\n",
        "name_lora_py = \"lora.py\"\n",
        "url_lora_py = horde_engine_url + model_manager_folder + name_lora_py\n",
        "path_lora_py = horde_engine_path + model_manager_folder + name_lora_py\n",
        "\n",
        "def download_files():\n",
        "    if (download_lora_py_bool):\n",
        "        download_file_wget(install_path = path_lora_py, download_url = url_lora_py)\n",
        "\n",
        "# Use the switches/toggles to download the file(s) as necessary\n",
        "#@markdown Only to download again the files affected by the edits, effectively reverting any changes made to them. Only for emergencies or if you know what you are doing\n",
        "download_lora_py_bool = False #@param {type:\"boolean\"}\n",
        "\n",
        "download_files()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJrOImdP1cCH"
      },
      "outputs": [],
      "source": [
        "# @title ## Function: edit file(s) { display-mode: \"form\" }\n",
        "def Edit_file_code(goal, target_file, target_code, new_code, lines_offset, pop_x_lines):\n",
        "\n",
        "    print(f'''-------------------------------------\n",
        "Purpose: {goal}\n",
        "target file: {target_file}\n",
        "target code:\\n{target_code}\n",
        "new code:\\n{new_code}\n",
        "lines offset: {lines_offset}\n",
        "{pop_x_lines} lines to pop''')\n",
        "\n",
        "    # check if the edit was already done, exit if so\n",
        "    with open(target_file, 'r') as file:\n",
        "        data = file.read()\n",
        "    if (new_code in data):\n",
        "        print (f'''The new code was found in target file: {target_file}. The edit was already done. Exiting.''')\n",
        "        return\n",
        "\n",
        "    # read the file\n",
        "    with open(target_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    found_line_number = -1\n",
        "\n",
        "    # find the target line \"target_code\"\n",
        "    for i, line in enumerate(lines):\n",
        "        if target_code in line:\n",
        "            found_line_number = i\n",
        "            break\n",
        "\n",
        "    # it should always find it, but whatever, insert \"new_code\" to the data\n",
        "    if found_line_number != -1:\n",
        "        if (pop_x_lines):\n",
        "            print (\"haa\")\n",
        "            for i in range(pop_x_lines):\n",
        "                lines.pop(found_line_number)\n",
        "        lines.insert(found_line_number + lines_offset, new_code)\n",
        "        print (f'''New code added to target file: {target_file}. File edited.''')\n",
        "    else:\n",
        "        print (f'''Could not find target code: {target_code}.''')\n",
        "\n",
        "    # rewrite target_file\n",
        "    with open(target_file, 'w') as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "\n",
        "# Changes/edits to the worker\n",
        "\"\"\"\n",
        "    Change default loras, ignore the long, useless, outdated, deprecated list\n",
        "\"\"\"\n",
        "def edit_lora_py_change_default_loras():\n",
        "    # variables\n",
        "    goal = \"Change default Loras list for mine\"\n",
        "    target_file = path_lora_py\n",
        "    target_code = '''            self._default_lora_ids = self._get_json(self.LORA_DEFAULTS)'''\n",
        "    new_code = r'''            self._default_lora_ids = [216620, 216590]\n",
        "'''\n",
        "    lines_offset = 0\n",
        "    pop_x_lines = 1\n",
        "    # call the edit file function\n",
        "    Edit_file_code(goal, target_file, target_code, new_code, lines_offset, pop_x_lines)\n",
        "\n",
        "\"\"\"\n",
        "    Increase Lora size limit to 1GB\n",
        "\"\"\"\n",
        "def edit_lora_py_increase_lora_size_limit():\n",
        "    # variables\n",
        "    goal = \"Increase Lora size limit to 1GB\"\n",
        "    target_file = path_lora_py\n",
        "    target_code = '''            and lora[\"versions\"][lora_version][\"size_mb\"] > 220'''\n",
        "    new_code = r'''            and lora[\"versions\"][lora_version][\"size_mb\"] > 1024\n",
        "'''\n",
        "    lines_offset = 0\n",
        "    pop_x_lines = 1\n",
        "    # call the edit file function\n",
        "    Edit_file_code(goal, target_file, target_code, new_code, lines_offset, pop_x_lines)\n",
        "\n",
        "\n",
        "# Execute all enabled edits\n",
        "def edit_files():\n",
        "    if (edit_lora_py_change_default_loras_bool):\n",
        "        edit_lora_py_change_default_loras()\n",
        "    if (edit_lora_py_increase_lora_size_limit_bool):\n",
        "        edit_lora_py_increase_lora_size_limit()\n",
        "\n",
        "edit_files()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwMyg3JN1xPv",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# @title 6.- Run download models { display-mode: \"form\" }\n",
        "\n",
        "# Make sure you have the correct path based on any `cd` commands above\n",
        "!cd /content\n",
        "\n",
        "!source ../regen/bin/activate;python download_models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRnzqILb1xPw",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# @title 7.- Run the worker { display-mode: \"form\" }\n",
        "\n",
        "# Make sure you have the correct path based on any `cd` commands above\n",
        "!cd /content\n",
        "\n",
        "if (outside_model and outside_model_name and outside_model_download_url):\n",
        "    Maintenance_Mode = True\n",
        "Set_Maintenance_Mode_function(Maintenance_Mode)\n",
        "\n",
        "# Stop any reamining threads, maybe\n",
        "stop_thread = True\n",
        "# Start the thread\n",
        "stop_thread = False\n",
        "# To periodically clear the logs\n",
        "# @markdown If this interval is changed to anything other than \"ignore\", it will override the value set on the first cell\n",
        "interval2 = \"ignore\" #@param [\"ignore\", \"\", 20, 30, 60, 120, 300, 1800, 3600]\n",
        "if (\"ignore\" in interval2):\n",
        "    try:\n",
        "        threading.Thread(target=clear_output_periodically, args=(int(interval),)).start()\n",
        "        print(f\"Logs (output only) will be cleared every {int(interval)} seconds\")\n",
        "    except:\n",
        "        print(\"Logs will not be deleted\")\n",
        "else:\n",
        "    try:\n",
        "        threading.Thread(target=clear_output_periodically, args=(int(interval2),)).start()\n",
        "        print(f\"Logs (output only) will be cleared every {int(interval2)} seconds\")\n",
        "    except:\n",
        "        print(\"Logs will not be deleted\")\n",
        "\n",
        "\n",
        "if (shorter_logs):\n",
        "    !source ../regen/bin/activate;python run_worker.py -vv\n",
        "else:\n",
        "    !source ../regen/bin/activate;python run_worker.py\n",
        "\n",
        "# Stop the thread when the cell is stopped.\n",
        "stop_thread = True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}